{"cells":[{"cell_type":"markdown","metadata":{"id":"21Ca4cSIC-xZ"},"source":["データの読み込みと前処理を行うためのnotebookです。  \n","モデルの学習と予測にはここで処理をかけたデータを利用するようにして下さい。"]},{"cell_type":"markdown","metadata":{"id":"Aic7aRj1C-xa"},"source":["## 必要なライブラリのimport"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":793,"status":"ok","timestamp":1718608865502,"user":{"displayName":"中川真代","userId":"03084239707687737130"},"user_tz":-540},"id":"5uU6ASfHC-xa"},"outputs":[],"source":["import warnings\n","import time\n","import sys\n","import datetime\n","import os\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import TruncatedSVD\n","warnings.simplefilter(action='ignore', category=FutureWarning)"]},{"cell_type":"markdown","metadata":{"id":"qV5q-K3IC-xb"},"source":["## データの読み込み"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1718608865503,"user":{"displayName":"中川真代","userId":"03084239707687737130"},"user_tz":-540},"id":"d4Wjclj3C-xb"},"outputs":[],"source":["def reduce_mem_usage(df, verbose=True):\n","    \"\"\"\n","    データフレームのメモリ使用量を減らす。\n","\n","    Parameters\n","    ----------\n","    df : pd.DataFrame\n","        メモリ使用量を削減したいデータフレーム。\n","    verbose : bool, optional\n","        メモリ使用量の削減結果を出力するかどうか（デフォルトは True）。\n","\n","    Returns\n","    -------\n","    pd.DataFrame\n","        メモリ使用量が削減されたデータフレーム。\n","    \"\"\"\n","\n","    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n","    start_mem = df.memory_usage().sum() / 1024**2\n","    for col in df.columns:\n","        col_type = df[col].dtypes\n","        if col_type in numerics:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if str(col_type)[:3] == 'int':\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    df[col] = df[col].astype(np.int8)\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    df[col] = df[col].astype(np.int16)\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    df[col] = df[col].astype(np.int32)\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    df[col] = df[col].astype(np.int64)\n","            else:\n","                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    df[col] = df[col].astype(np.float16)\n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    df[col] = df[col].astype(np.float32)\n","                else:\n","                    df[col] = df[col].astype(np.float64)\n","    end_mem = df.memory_usage().sum() / 1024**2\n","    if verbose:\n","        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n","    return df\n","\n","\n","def binarize(df):\n","    \"\"\"\n","    指定された列を二値化する。\n","\n","    Parameters\n","    ----------\n","    df : pd.DataFrame\n","        二値化対象のデータフレーム。\n","\n","    Returns\n","    -------\n","    pd.DataFrame\n","        二値化されたデータフレーム。\n","    \"\"\"\n","\n","    for col in ['authorized_flag', 'category_1']:\n","        df[col] = df[col].map({'Y': 1, 'N': 0})\n","    return df\n","\n","\n","# 追加\n","def binarize_bool(df,bool_col):\n","    \"\"\"\n","    指定された列を二値化する。\n","\n","    Parameters\n","    ----------\n","    df : pd.DataFrame\n","        二値化対象のデータフレーム。\n","\n","    Returns\n","    -------\n","    pd.DataFrame\n","        二値化されたデータフレーム。\n","    \"\"\"\n","\n","    for col in bool_col:\n","        if col in df.columns:  # 列が存在することを確認\n","            df[col] = df[col].map({True: 1, False: 0})\n","        else:\n","            print(f\"Warning: Column '{col}' does not exist in the DataFrame.\")\n","    return df\n","\n","def read_data(input_file):\n","    \"\"\"\n","    指定されたファイルからデータを読み込み、前処理を行う。\n","\n","    Parameters\n","    ----------\n","    input_file : str\n","        読み込むデータファイルのパス。\n","\n","    Returns\n","    -------\n","    pd.DataFrame\n","        前処理されたデータフレーム。\n","    \"\"\"\n","\n","    df = pd.read_csv(input_file)\n","    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n","    # 基準日(2018-02-01)からの日付差(データが存在する最終日らしい)\n","    df['elapsed_time'] = (pd.Timestamp('2018-02-01') - df['first_active_month']).dt.days\n","    return df"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# windows\n","if os.name == 'nt':\n","    path = '../../../data/elo-merchant-category-recommendation/'\n","else:\n","    if 'KAGGLE_DATA_PROXY_TOKEN' in os.environ.keys():\n","        path = '/kaggle/input/elo-merchant-category-recommendaton/'\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"xoHgqMb1C-xb"},"outputs":[],"source":["train_path = os.path.join(path, 'train.csv')\n","test_path = os.path.join(path,'test.csv')\n","outlier_path = os.path.join(path,'outlier_flag.csv')\n","new_transactions_path = os.path.join(path,'new_merchant_transactions.csv')\n","historical_transactions_path = os.path.join(path,'historical_transactions.csv')\n","\n","train = read_data(train_path)\n","test = read_data(test_path)\n","new_transactions = pd.read_csv(new_transactions_path,\n","                               parse_dates=['purchase_date'])\n","\n","historical_transactions = pd.read_csv(historical_transactions_path,\n","                                      parse_dates=['purchase_date'])\n","\n","# N,Yを0,1に変換\n","historical_transactions = binarize(historical_transactions)\n","new_transactions = binarize(new_transactions)"]},{"cell_type":"markdown","metadata":{"id":"rLZKA2mjC-xb"},"source":["## 特徴量作成"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"rAS3vGz3C-xb"},"outputs":[],"source":["# mode関数を追加\n","def mode(series):\n","    return series.mode().iloc[0]  # modeが複数ある場合、最初のものを選ぶ\n","\n","def calculate_month_diff(transactions):\n","    \"\"\"\n","    purchase_dateとmonth_lagを基にmonth_diffを計算する。\n","\n","    Parameters\n","    ----------\n","    transactions : pd.DataFrame\n","        取引データのデータフレーム。\n","\n","    Returns\n","    -------\n","    pd.DataFrame\n","        month_diff列が追加されたデータフレーム。\n","    \"\"\"\n","    current_date = pd.Timestamp('2018-02-01') # 今日…今日？？？-> 基準日(2018-02-01)にしてみた\n","    transactions['month_diff'] = ((current_date - transactions['purchase_date']).dt.days) // 30\n","    transactions['month_diff'] += transactions['month_lag']\n","    return transactions\n","\n","\n","def encode_categorical_columns(df, columns):\n","    \"\"\"\n","    指定されたカテゴリカル列をワンホットエンコーディングする。\n","\n","    Parameters\n","    ----------\n","    df : pd.DataFrame\n","        エンコード対象のデータフレーム。\n","    columns : list of str\n","        エンコードするカテゴリカル列のリスト。\n","\n","    Returns\n","    -------\n","    pd.DataFrame\n","        ワンホットエンコードされたデータフレーム。\n","    \"\"\"\n","    return pd.get_dummies(df, columns=columns)\n","\n","\n","def reduce_mem_usage(df, verbose=True):\n","    \"\"\"\n","    データフレームのメモリ使用量を減らす。\n","\n","    Parameters\n","    ----------\n","    df : pd.DataFrame\n","        メモリ使用量を削減したいデータフレーム。\n","    verbose : bool, optional\n","        メモリ使用量の削減結果を出力するかどうか（デフォルトは True）。\n","\n","    Returns\n","    -------\n","    pd.DataFrame\n","        メモリ使用量が削減されたデータフレーム。\n","    \"\"\"\n","    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n","    start_mem = df.memory_usage().sum() / 1024**2\n","    for col in df.columns:\n","        col_type = df[col].dtypes\n","        if col_type in numerics:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if str(col_type)[:3] == 'int':\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    df[col] = df[col].astype(np.int8)\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    df[col] = df[col].astype(np.int16)\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    df[col] = df[col].astype(np.int32)\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    df[col] = df[col].astype(np.int64)\n","            else:\n","                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    df[col] = df[col].astype(np.float16)\n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    df[col] = df[col].astype(np.float32)\n","                else:\n","                    df[col] = df[col].astype(np.float64)\n","    end_mem = df.memory_usage().sum() / 1024**2\n","    if verbose:\n","        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n","    return df\n","\n","\n","def aggregate_transactions(history):\n","    \"\"\"\n","    取引データを集計する。\n","\n","    Parameters\n","    ----------\n","    history : pd.DataFrame\n","        取引データのデータフレーム。\n","\n","    Returns\n","    -------\n","    pd.DataFrame\n","        集計されたデータフレーム。\n","    \"\"\"\n","    history.loc[:, 'purchase_date'] = pd.DatetimeIndex(history['purchase_date']).astype(np.int64) * 1e-9\n","    # modeを追加\n","    agg_func = {\n","        'category_1': ['sum', 'mean',mode],\n","        'category_2_1.0': ['mean',mode],\n","        'category_2_2.0': ['mean',mode],\n","        'category_2_3.0': ['mean',mode],\n","        'category_2_4.0': ['mean',mode],\n","        'category_2_5.0': ['mean',mode],\n","        'category_3_A': ['mean',mode],\n","        'category_3_B': ['mean',mode],\n","        'category_3_C': ['mean',mode],\n","        'merchant_id': ['nunique'],\n","        'merchant_category_id': ['nunique'],\n","        'state_id': ['nunique'],\n","        'city_id': ['nunique'],\n","        'subsector_id': ['nunique'],\n","        'purchase_amount': ['sum', 'mean', 'max', 'min', 'std',mode],\n","        'installments': ['sum', 'mean', 'max', 'min', 'std',mode],\n","        'purchase_month': ['mean', 'max', 'min', 'std',mode],\n","        # ptpはmaxとminの差らしい\n","        'purchase_date': [np.ptp, 'min', 'max',mode],\n","        'month_lag': ['mean', 'max', 'min', 'std',mode],\n","        'month_diff': ['mean']\n","    }\n","\n","    agg_history = history.groupby(['card_id']).agg(agg_func)\n","    agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n","    agg_history.reset_index(inplace=True)\n","\n","    df = (history.groupby('card_id')\n","          .size()\n","          .reset_index(name='transactions_count'))\n","\n","    agg_history = pd.merge(df, agg_history, on='card_id', how='left')\n","\n","    return agg_history\n","\n","\n","def aggregate_per_month(history):\n","    \"\"\"\n","    月ごとの取引データを集計する。\n","\n","    Parameters\n","    ----------\n","    history : pd.DataFrame\n","        取引データのデータフレーム。\n","\n","    Returns\n","    -------\n","    pd.DataFrame\n","        月ごとに集計されたデータフレーム。\n","    \"\"\"\n","    grouped = history.groupby(['card_id', 'month_lag'])\n","\n","    agg_func = {\n","        'purchase_amount': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n","        'installments': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n","    }\n","\n","    intermediate_group = grouped.agg(agg_func)\n","    intermediate_group.columns = ['_'.join(col).strip() for col in intermediate_group.columns.values]\n","    intermediate_group.reset_index(inplace=True)\n","\n","    final_group = intermediate_group.groupby('card_id').agg(['mean', 'std'])\n","    final_group.columns = ['_'.join(col).strip() for col in final_group.columns.values]\n","    final_group.reset_index(inplace=True)\n","\n","    return final_group\n","\n","\n","def successive_aggregates(df, field1, field2):\n","    \"\"\"\n","    指定されたフィールドを基に連続集計を行う。\n","    要は2値グループバイしたmeanとminとmaxとstdを出す関数ってことね\n","    Parameters\n","    ----------\n","    df : pd.DataFrame\n","        取引データのデータフレーム。\n","    field1 : str\n","        集計の基準となるフィールド。\n","    field2 : str\n","        集計されるフィールド。\n","\n","    Returns\n","    -------\n","    pd.DataFrame\n","        連続集計されたデータフレーム。\n","    \"\"\"\n","    t = df.groupby(['card_id', field1])[field2].mean()\n","    u = pd.DataFrame(t).reset_index().groupby('card_id')[field2].agg(['mean', 'min', 'max', 'std'])\n","    u.columns = [field1 + '_' + field2 + '_' + col for col in u.columns.values]\n","    u.reset_index(inplace=True)\n","    return u\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"nfELtRlYC-xc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mem. usage decreased to 1332.66 Mb (57.1% reduction)\n","Mem. usage decreased to 86.12 Mb (58.9% reduction)\n"]}],"source":["# データ準備\n","historical_transactions['purchase_date'] = pd.to_datetime(historical_transactions['purchase_date'])\n","new_transactions['purchase_date'] = pd.to_datetime(new_transactions['purchase_date'])\n","\n","# 月の差を計算\n","historical_transactions = calculate_month_diff(historical_transactions)\n","new_transactions = calculate_month_diff(new_transactions)\n","\n","# カテゴリカル列をワンホットエンコーディング\n","historical_transactions = encode_categorical_columns(historical_transactions, ['category_2', 'category_3'])\n","new_transactions = encode_categorical_columns(new_transactions, ['category_2', 'category_3'])\n","\n","# メモリ使用量の削減\n","historical_transactions = reduce_mem_usage(historical_transactions)\n","new_transactions = reduce_mem_usage(new_transactions)\n","\n","# authorized_flagの平均を計算\n","agg_fun = {'authorized_flag': ['mean']}\n","auth_mean = historical_transactions.groupby(['card_id']).agg(agg_fun)\n","auth_mean.columns = ['_'.join(col).strip() for col in auth_mean.columns.values]\n","auth_mean.reset_index(inplace=True)\n","\n","# authorized_flagに基づいてデータを分割\n","authorized_transactions = historical_transactions[historical_transactions['authorized_flag'] == 1]\n","historical_transactions = historical_transactions[historical_transactions['authorized_flag'] == 0]\n","\n","# purchase_month列を追加\n","historical_transactions['purchase_month'] = historical_transactions['purchase_date'].dt.month\n","authorized_transactions['purchase_month'] = authorized_transactions['purchase_date'].dt.month\n","new_transactions['purchase_month'] = new_transactions['purchase_date'].dt.month\n","\n","# データの集計\n","history = aggregate_transactions(historical_transactions)\n","history.columns = ['hist_' + c if c != 'card_id' else c for c in history.columns]\n","\n","# rankの設定\n","history['month_rank'] = historical_transactions.groupby(['card_id'])['month_lag'].rank(method='dense',ascending=False)\n","history['date_rank'] = historical_transactions.groupby(['card_id'])['purchase_date'].rank(method='dense',ascending=False)\n","\n","\n","authorized = aggregate_transactions(authorized_transactions)\n","authorized.columns = ['auth_' + c if c != 'card_id' else c for c in authorized.columns]\n","\n","new = aggregate_transactions(new_transactions)\n","new.columns = ['new_' + c if c != 'card_id' else c for c in new.columns]\n","\n","# 月ごとのデータの集計\n","final_group = aggregate_per_month(authorized_transactions)\n","\n","# 連続集計(new_transactionにくっつけてく)\n","additional_fields = successive_aggregates(new_transactions, 'category_1', 'purchase_amount')\n","additional_fields = pd.merge(additional_fields, successive_aggregates(new_transactions, 'installments', 'purchase_amount'), on='card_id', how='left')\n","additional_fields = pd.merge(additional_fields, successive_aggregates(new_transactions, 'city_id', 'purchase_amount'), on='card_id', how='left')\n","additional_fields = pd.merge(additional_fields, successive_aggregates(new_transactions, 'category_1', 'installments'), on='card_id', how='left')"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":7,"metadata":{"id":"h3f7RXZOC-xc"},"outputs":[],"source":["# データの結合\n","train = pd.merge(train, history, on='card_id', how='left')\n","test = pd.merge(test, history, on='card_id', how='left')\n","\n","train = pd.merge(train, authorized, on='card_id', how='left')\n","test = pd.merge(test, authorized, on='card_id', how='left')\n","\n","train = pd.merge(train, new, on='card_id', how='left')\n","test = pd.merge(test, new, on='card_id', how='left')\n","\n","train = pd.merge(train, final_group, on='card_id', how='left')\n","test = pd.merge(test, final_group, on='card_id', how='left')\n","\n","train = pd.merge(train, auth_mean, on='card_id', how='left')\n","test = pd.merge(test, auth_mean, on='card_id', how='left')\n","\n","train = pd.merge(train, additional_fields, on='card_id', how='left')\n","test = pd.merge(test, additional_fields, on='card_id', how='left')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# rate特徴量の追加\n","train['rate_new/hist_purchase_date_max'] = train['new_purchase_date_max']/train['hist_purchase_date_max']\n","test['rate_new/hist_purchase_date_max'] = test['new_purchase_date_max']/test['hist_purchase_date_max']\n","\n","train['rate_new/hist_month_diff_mean'] = train['new_month_diff_mean']/train['hist_month_diff_mean']\n","test['rate_new/hist_month_diff_mean'] = test['new_month_diff_mean']/test['hist_month_diff_mean']\n","\n","train['rate_new/hist_purchase_amount_sum'] = train['new_purchase_amount_sum']/train['hist_purchase_amount_sum']\n","test['rate_new/hist_purchase_amount_sum'] = test['new_purchase_amount_sum']/test['hist_purchase_amount_sum']\n","\n","train['rate_new/hist_purchase_amount_max'] = train['new_purchase_amount_max']/train['hist_purchase_amount_max']\n","test['rate_new/hist_purchase_amount_max'] = test['new_purchase_amount_max']/test['hist_purchase_amount_max']\n","\n","train['rate_new/hist_purchase_amount_mean'] = train['new_purchase_amount_mean']/train['hist_purchase_amount_mean']\n","test['rate_new/hist_purchase_amount_mean'] = test['new_purchase_amount_mean']/test['hist_purchase_amount_mean']"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["# 追加　True,Falseの変換\n","bool_col = ['hist_category_2_1.0_mode','hist_category_2_2.0_mode','hist_category_2_3.0_mode','hist_category_2_4.0_mode','hist_category_2_5.0_mode','hist_category_3_A_mode','hist_category_3_B_mode','hist_category_3_C_mode','new_category_2_1.0_mode','new_category_2_2.0_mode','new_category_2_3.0_mode','new_category_2_4.0_mode','new_category_2_5.0_mode','new_category_3_A_mode','new_category_3_B_mode','new_category_3_C_mode']\n","\n","train = binarize_bool(df=train,bool_col=bool_col)\n","test = binarize_bool(df=test,bool_col=bool_col)"]},{"cell_type":"markdown","metadata":{"id":"cYIBOEB1C-xd"},"source":["## 前処理終了後のデータの保存\n","- 基本的にモデルの学習・ハイパーパラメータチューニングを行う際にはここで作成した同じデータを使い回して下さい。\n","- 適宜前処理を変更した場合はファイル名を変えるなどして管理して下さい。"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["train.to_csv('../../../data/processed/processed20240620_train.csv',index=None)\n","test.to_csv('../../../data/processed/processed20240620_test.csv',index=None)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
